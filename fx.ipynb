{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWtKoPaHRqQEb7aE6D8Gla",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManjuRama/FinMath/blob/main/fx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8xjteYrWGng"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statsmodels.tsa.api import VAR\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset (replace with your actual file paths)\n",
        "data_usdchf = pd.read_csv('USDCHF_data.csv', parse_dates=['timestamp'], index_col='timestamp')\n",
        "data_gbpusd = pd.read_csv('GBPUSD_data.csv', parse_dates=['timestamp'], index_col='timestamp')\n",
        "data_eurusd = pd.read_csv('EURUSD_data.csv', parse_dates=['timestamp'], index_col='timestamp')\n",
        "\n",
        "# Function to preprocess and prepare the data for VAR model\n",
        "def prepare_data_for_VAR(data, target_col, lag_hours=1):\n",
        "    \"\"\"\n",
        "    Prepare data for VAR modeling.\n",
        "    - data: FX pair data containing volume, spread, mid quote\n",
        "    - target_col: column name of the target variable (next hour volume)\n",
        "    - lag_hours: number of hours to lag the data (default is 1)\n",
        "    \"\"\"\n",
        "    # Create lag features\n",
        "    data_lagged = data.copy()\n",
        "    for i in range(1, lag_hours * 60 + 1):  # Create lag for each minute in the past hour\n",
        "        data_lagged[f'volume_lag_{i}'] = data_lagged['volume_last_minute'].shift(i)\n",
        "        data_lagged[f'spread_lag_{i}'] = data_lagged['spread'].shift(i)\n",
        "        data_lagged[f'midquote_lag_{i}'] = data_lagged['mid_quote'].shift(i)\n",
        "\n",
        "    # Drop rows with NaN values due to shifting\n",
        "    data_lagged.dropna(inplace=True)\n",
        "\n",
        "    # Separate into train and test sets\n",
        "    train_size = int(0.8 * len(data_lagged))\n",
        "    train_data = data_lagged[:train_size]\n",
        "    test_data = data_lagged[train_size:]\n",
        "\n",
        "    # Features and target (next hour volume)\n",
        "    X_train = train_data.drop(columns=[target_col])\n",
        "    y_train = train_data[target_col]\n",
        "    X_test = test_data.drop(columns=[target_col])\n",
        "    y_test = test_data[target_col]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# Function to fit VAR model and predict next hour volume\n",
        "def fit_VAR_and_predict(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Fit VAR model and predict next hour volume.\n",
        "    - X_train, y_train: Training data\n",
        "    - X_test, y_test: Test data\n",
        "    \"\"\"\n",
        "    # Combine features and target into one dataframe for VAR modeling\n",
        "    train_data = pd.concat([X_train, y_train], axis=1)\n",
        "    model = VAR(train_data)\n",
        "\n",
        "    # Fit the model\n",
        "    model_fitted = model.fit(maxlags=60, ic='aic')\n",
        "\n",
        "    # Generate predictions\n",
        "    lag_order = model_fitted.k_ar\n",
        "    forecast_input = train_data.values[-lag_order:]\n",
        "    forecast = model_fitted.forecast(y=forecast_input, steps=len(X_test))\n",
        "\n",
        "    # Convert forecasted results into a DataFrame\n",
        "    forecast_df = pd.DataFrame(forecast, index=X_test.index, columns=train_data.columns)\n",
        "\n",
        "    # Calculate MAPE\n",
        "    mape = mean_absolute_percentage_error(y_test, forecast_df[y_test.name])\n",
        "\n",
        "    return forecast_df[y_test.name], mape\n",
        "\n",
        "# Prepare and predict for each FX pair\n",
        "for pair, data in [('USDCHF', data_usdchf), ('GBPUSD', data_gbpusd), ('EURUSD', data_eurusd)]:\n",
        "    print(f'Predicting for {pair}...')\n",
        "\n",
        "    # Prepare data\n",
        "    X_train, y_train, X_test, y_test = prepare_data_for_VAR(data, target_col='volume_last_hour')\n",
        "\n",
        "    # Fit VAR model and predict\n",
        "    predicted_volume, mape = fit_VAR_and_predict(X_train, y_train, X_test, y_test)\n",
        "\n",
        "    print(f'{pair} - MAPE: {mape:.4f}')\n",
        "\n",
        "    # Optional: plot actual vs predicted\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(y_test.index, y_test, label='Actual Volume')\n",
        "    plt.plot(predicted_volume.index, predicted_volume, label='Predicted Volume', linestyle='--')\n",
        "    plt.title(f'{pair} - Actual vs Predicted Next Hour Volume')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    }
  ]
}